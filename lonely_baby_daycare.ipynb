{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ae5b30",
   "metadata": {},
   "source": [
    "## Google Drive Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc49869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Authentication Complete! **\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "\n",
    "creds = None\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "\n",
    "try:\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "    service_sheets = build('sheets', 'v4', credentials=creds)\n",
    "    \n",
    "    print(\"** Authentication Complete! **\")\n",
    "\n",
    "except HttpError as error:\n",
    "    # TODO(developer) - Handle errors from drive API.\n",
    "    print(f'An error occurred: {error}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c13f1",
   "metadata": {},
   "source": [
    "## Google Drive API helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a90598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from os import listdir\n",
    "\n",
    "def getFolderId(service, folderName: str):\n",
    "    query = \"name contains '%s' and mimeType = '%s'\" % (folderName, 'application/vnd.google-apps.folder')\n",
    "\n",
    "    fid = None\n",
    "\n",
    "    if folderName.startswith('+'):\n",
    "        return (folderName[1:])\n",
    "\n",
    "    result = service.files().list(q=query,\n",
    "                                  pageSize=10, pageToken='',\n",
    "                                  fields=\"nextPageToken,files(parents,id,name,mimeType)\").execute()\n",
    "  \n",
    "    if len(result['files']) == 0:\n",
    "        print(\"Folder NOT found\")\n",
    "    else:\n",
    "        folder = result.get('files')[0]\n",
    "        fid = folder['id']\n",
    "\n",
    "    return (fid)\n",
    "\n",
    "    \n",
    "def downloadFolder(service, fileId, destinationFolder):\n",
    "    if not os.path.isdir(destinationFolder):\n",
    "        os.mkdir(path=destinationFolder)\n",
    "\n",
    "    results = service.files().list(\n",
    "        pageSize=300,\n",
    "        q=\"parents in '{0}'\".format(fileId),\n",
    "        fields=\"files(id, name, mimeType)\"\n",
    "        ).execute()\n",
    "\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    for item in items:\n",
    "        itemName = item['name']\n",
    "        itemId = item['id']\n",
    "        itemType = item['mimeType']\n",
    "        filePath = destinationFolder + \"/\" + itemName\n",
    "\n",
    "        if itemType == 'application/vnd.google-apps.folder':\n",
    "            downloadFolder(service, itemId, filePath) # Recursive call\n",
    "            print(\"Downloaded folder: {0}\".format(itemName))\n",
    "        elif not itemType.startswith('application/'):\n",
    "            downloadFile(service, itemId, filePath)\n",
    "        else:\n",
    "            print(\"Unsupported file: {0}\".format(itemName))\n",
    "\n",
    "\n",
    "def downloadFile(service, fileId, filePath):\n",
    "    # Note: The parent folders in filePath must exist\n",
    "    request = service.files().get_media(fileId=fileId)\n",
    "    fh = io.FileIO(filePath, mode='wb')\n",
    "    \n",
    "    try:\n",
    "        downloader = MediaIoBaseDownload(fh, request, chunksize=1024*1024)\n",
    "\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk(num_retries = 2)\n",
    "    finally:\n",
    "        fh.close()\n",
    "        \n",
    "def deleteFilesInFolder(folder_id):\n",
    "    results = service.files().list(\n",
    "        pageSize=300,\n",
    "        q=\"parents in '{0}'\".format(folder_id),\n",
    "        fields=\"files(id, name, mimeType)\"\n",
    "        ).execute()\n",
    "\n",
    "    items = results.get('files', [])\n",
    "    for item in items:\n",
    "        itemId = item['id']\n",
    "        service.files().delete(fileId=itemId).execute()\n",
    "        \n",
    "def uploadFolder(service, folder_id, src_folder):        \n",
    "    for file in listdir(src_folder):\n",
    "        print('Uploading: ' + file)\n",
    "        file_metadata = {'name': file, 'parents': [folder_id]}\n",
    "        media = MediaFileUpload(os.path.join(src_folder, file), mimetype='image/png')\n",
    "        file = service.files().create(body=file_metadata,\n",
    "                                    media_body=media,\n",
    "                                    fields='id').execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec2e81",
   "metadata": {},
   "source": [
    "## Download Trait Files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13192f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded folder: ears\n",
      "Downloaded folder: patch\n",
      "Downloaded folder: satchels\n",
      "Downloaded folder: quarter zip\n",
      "Downloaded folder: upper + lower\n",
      "Downloaded folder: short pants\n",
      "Downloaded folder: hats + face\n",
      "Downloaded folder: pillow\n",
      "Downloaded folder: headphones\n",
      "Downloaded folder: spilled carton\n",
      "Downloaded folder: bucket hats\n",
      "Downloaded folder: Flag Patches\n",
      "Downloaded folder: Patches\n",
      "Downloaded folder: beanies\n",
      "Downloaded folder: Patches\n",
      "Downloaded folder: baseball cap\n",
      "Downloaded folder: hats\n",
      "Downloaded folder: walkman\n",
      "Downloaded folder: halo\n",
      "Downloaded folder: dots\n",
      "Downloaded folder: healthbar\n",
      "Downloaded folder: external\n",
      "Downloaded folder: chinese mask\n",
      "Downloaded folder: syringe\n",
      "Downloaded folder: sticky notes\n",
      "Downloaded folder: glasses\n",
      "Downloaded folder: fb\n",
      "Downloaded folder: surgical masks\n",
      "Downloaded folder: face\n",
      "Downloaded folder: satchels\n",
      "Downloaded folder: Meta Tees\n",
      "Downloaded folder: short sleeves\n",
      "Downloaded folder: fat pants\n",
      "Downloaded folder: NB Sneakers\n",
      "Downloaded folder: AirForce1\n",
      "Downloaded folder: shoes\n",
      "Downloaded folder: Sweatpants LP\n",
      "Downloaded folder: Sweatpants Plain\n",
      "Downloaded folder: slim pants\n",
      "Downloaded folder: satchels\n",
      "Downloaded folder: undergarment upper\n",
      "Downloaded folder: undergarment lower\n",
      "Downloaded folder: lick\n",
      "Downloaded folder: bawl\n",
      "Downloaded folder: laugh\n",
      "Downloaded folder: grin\n",
      "Downloaded folder: angry\n",
      "Downloaded folder: crying\n",
      "Downloaded folder: neutral\n",
      "Downloaded folder: eaten catalien\n",
      "Downloaded folder: eaten\n",
      "Downloaded folder: body\n",
      "Downloaded folder: satchels\n",
      "Downloaded folder: hoodies\n",
      "Downloaded folder: satchels\n",
      "Downloaded folder: dress shirt\n",
      "\n",
      "** Download Complete! **\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "traits_base_filepath = 'Traits'\n",
    "\n",
    "# Delete previously downloaded trait files\n",
    "if os.path.isdir(traits_base_filepath):\n",
    "    shutil.rmtree(traits_base_filepath)\n",
    "\n",
    "traits_folder_id = getFolderId(service, traits_base_filepath)\n",
    "\n",
    "downloadFolder(service, traits_folder_id, traits_base_filepath)\n",
    "\n",
    "print(\"\\n** Download Complete! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705b154",
   "metadata": {},
   "source": [
    "## Print all folders, files (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d2d2c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short pants\n",
      "hoodies\n",
      "quarter zip\n",
      "face\n",
      "short sleeves\n",
      "hats\n",
      "body\n",
      "upper + lower\n",
      "ears\n",
      "fat pants\n",
      "slim pants\n",
      "dress shirt\n",
      "undergarment upper\n",
      "hats + face\n",
      "external\n",
      "shoes\n",
      "undergarment lower\n",
      "shorts_black.PNG\n",
      "shorts_grey.PNG\n",
      "shorts_red.PNG\n",
      "shorts_brown.PNG\n",
      "shorts_blue.PNG\n",
      "shorts_purple.PNG\n",
      "shorts_green.PNG\n",
      "Hoodies Plain\n",
      "Hoodies LP\n",
      "quarterzip_red.PNG\n",
      "quarterzip_pink.PNG\n",
      "quarterzip_purple.PNG\n",
      "quarterzip_green.PNG\n",
      "quarterzip_grey.PNG\n",
      "surgical masks\n",
      "fb\n",
      "sticky notes\n",
      "glasses\n",
      "syringe\n",
      "Meta Tees\n",
      "baseball cap\n",
      "bucket hats\n",
      "beanies\n",
      "headphones\n",
      "pillow_white.PNG\n",
      "spilled carton\n",
      "eaten\n",
      "eaten catalien\n",
      "crying\n",
      "grin\n",
      "neutral\n",
      "angry\n",
      "laugh\n",
      "charlesharness_red.PNG\n",
      "earrings\n",
      "earbleed_white.PNG\n",
      "jeans_lightblue.PNG\n",
      "jeans_darkblue.PNG\n",
      "Sweatpants Plain\n",
      "Sweatpants LP\n",
      "dressshirt_pink.PNG\n",
      "dressshirt_grey.PNG\n",
      "wifebeater_pink.png\n",
      "wifebeater_white.png\n",
      "Space_Helmet.PNG\n",
      "walkman_green.PNG\n",
      "dots\n",
      "halo_yellow.PNG\n",
      "healthbar\n",
      "NB Sneakers\n",
      "AirForce1\n",
      "underwear_grey.png\n",
      "underwear_white.png\n",
      "Hoodie_Green.PNG\n",
      "Hoodie_Vanilla.PNG\n",
      "Hoodie_Grey.PNG\n",
      "Hoodie_White_Patches.PNG\n",
      "HoodieLP_Grey_Yellow.PNG\n",
      "HoodieLP_Green_Red.PNG\n",
      "HoodieLP_Grey_Red.PNG\n",
      "HoodieLP_Vanilla_Black.PNG\n",
      "HoodieLP_Vanilla_Blue.PNG\n",
      "HoodieLP_Vanilla_Pink.PNG\n",
      "HoodieLP_Green_Grey.PNG\n",
      "HoodieLP_Vanilla_Red.PNG\n",
      "surgicalmaskunderchin_blue.PNG\n",
      "surgicalmaskundernose_blue.PNG\n",
      "surgicalmaskovernose_blue.PNG\n",
      "fboffline.PNG\n",
      "fbonline.PNG\n",
      "stickyTwo_blue.PNG\n",
      "stickyNumber_purple.PNG\n",
      "stickyTwo_orange.PNG\n",
      "stickySmile_orange.PNG\n",
      "stickySmile_purple.PNG\n",
      "stickyTwo_purple.PNG\n",
      "stickyNumber_orange.PNG\n",
      "stickNumber_blue.PNG\n",
      "stickySmile_blue.PNG\n",
      "glassesSquare_clear.PNG\n",
      "glassesSlim_clear.PNG\n",
      "glassesSquare_lightorange.PNG\n",
      "glassesSquare_orange.PNG\n",
      "glassesSquare_purple.PNG\n",
      "glasses3D_square.PNG\n",
      "glassesSlim_orange.PNG\n",
      "glassesSlim_grey.PNG\n",
      "glassesSquare_pink.PNG\n",
      "glassesSlim_pink.PNG\n",
      "glassesSquare_grey.PNG\n",
      "glasses3D_slim.PNG\n",
      "GlassesSlim_green.PNG\n",
      "glassesSquare_green.PNG\n",
      "syringeLeftCheek.PNG\n",
      "syringeRightCheek.PNG\n",
      "syringerRightLip.PNG\n",
      "metaTee_pink.PNG\n",
      "metaTee_red.PNG\n",
      "metaTee_lightblue.PNG\n",
      "metaTee_darkblue.PNG\n",
      "metaTee_green.PNG\n",
      "metaTee_grey.PNG\n",
      "BaseballCap_Grey.PNG\n",
      "Patches\n",
      "BaseballCap_Black.PNG\n",
      "BucketHat_Black.PNG\n",
      "BucketHat_Green.PNG\n",
      "Beanie_BrightOrange.PNG\n",
      "Patches\n",
      "Beanie_Grey.PNG\n",
      "Beanie_Green.png\n",
      "Beanie_Red.PNG\n",
      "Beanie_Vanilla.PNG\n",
      "headphones_purple.PNG\n",
      "headphones_black.PNG\n",
      "headphones_blue.PNG\n",
      "headphones_yellow.PNG\n",
      "SpilledCarton_Milk.PNG\n",
      "SpilledCarton_Coco.PNG\n",
      "SpilledCarton_OJ.PNG\n",
      "bodyeaten_yellow_yellow.png\n",
      "bodyeaten_blue_yellow.png\n",
      "bodyeaten_yellow_blue.png\n",
      "bodyeaten_yellow_pink.png\n",
      "bodyeaten_yellow_red.png\n",
      "bodyeaten_yellow_green.png\n",
      "bodyeaten_pink_yellow.png\n",
      "bodyeaten_red_yellow.png\n",
      "bodyeaten_yellow_grey.png\n",
      "bodyeaten_green_yellow.png\n",
      "bodyeaten_grey_yellow.png\n",
      "bodycateaten_green.PNG\n",
      "bodycateaten_beige.PNG\n",
      "bodycateaten_lightclay.PNG\n",
      "bodycateaten_purple.PNG\n",
      "bodycateaten_black.PNG\n",
      "bodycrying_blue.PNG\n",
      "bodycrying_pink.PNG\n",
      "bodygrin_blue.PNG\n",
      "bodygrin_pink.PNG\n",
      "bodygrin_yellow.PNG\n",
      "bodyneutral_yellow.PNG\n",
      "bodyneutral_pink.PNG\n",
      "bodyneutral_blue.PNG\n",
      "bodyangry_blue.png\n",
      "bodylaugh_pink.PNG\n",
      "bodylaugh_blue.PNG\n",
      "bodylaugh_yellow.PNG\n",
      "earringStudLeft.PNG\n",
      "earringRingLeftUpper.PNG\n",
      "earringStudRight.PNG\n",
      "earringRingLeftLower.PNG\n",
      "earringCrossRight.PNG\n",
      "earringRingRightLower.PNG\n",
      "earringCrossLeft.PNG\n",
      "earringRingRightUpper.PNG\n",
      "sweatpants_grey.PNG\n",
      "sweatpants_white.PNG\n",
      "sweatpants_green.PNG\n",
      "sweatpantsLP_green_red.PNG\n",
      "sweatpantsLP_white_red.PNG\n",
      "sweatpantsLP_green_yellow.PNG\n",
      "sweatpantsLP_grey_yellow.PNG\n",
      "sweatpantsLP_white_yellow.PNG\n",
      "sweatpantsLP_white_pink.PNG\n",
      "sweatpantsLP_white_blue.PNG\n",
      "sweatpantsLP_grey_black.PNG\n",
      "sweatpantsLP_white_black.PNG\n",
      "sweatpantsLP_green_pink.PNG\n",
      "sweatpantsLP_green_blue.PNG\n",
      "sweatpantsLP_green_black.PNG\n",
      "sweatpantsLP_grey_pink.PNG\n",
      "sweatpantsLP_grey_blue.PNG\n",
      "externaldots_red_pink.PNG\n",
      "externaldots_red_green.PNG\n",
      "healthbar_green.PNG\n",
      "healthbar_yellow.PNG\n",
      "healthbar_red.PNG\n",
      "NBSneakers_tropical.PNG\n",
      "AF1_purple.PNG\n",
      "AF1_orange.PNG\n",
      "AF1_black.PNG\n",
      "AF1_grey.PNG\n",
      "AF1_green.PNG\n",
      "AF1_red.PNG\n",
      "BaseballCapPatch_USA.PNG\n",
      "BaseballCapPatch_USAGrey.PNG\n",
      "Flag Patches\n",
      "BeaniePatch_UK.PNG\n",
      "BeanieFlag_USA.PNG\n",
      "BeaniePatch_Mexico.PNG\n",
      "BeaniePatch_Nigeria.PNG\n",
      "BeaniePatch_Russia.PNG\n",
      "BeaniePatch_Taiwan.PNG\n",
      "BeaniePatch_Italy.PNG\n",
      "BeaniePatch_India.PNG\n",
      "BeaniePatch_Vietnam.PNG\n",
      "BeaniePatch_Korea.PNG\n"
     ]
    }
   ],
   "source": [
    "folder_queue = [traits_base_filepath]\n",
    "\n",
    "#Generate rarity definitions\n",
    "while folder_queue:\n",
    "    curr_folder = folder_queue.pop(0)\n",
    "    \n",
    "    files = os.listdir(curr_folder)\n",
    "    files = filter(lambda file: not file.startswith('.'), files)\n",
    "    \n",
    "    for file in files:\n",
    "        print(file)\n",
    "        if not file.lower().endswith('.png'):\n",
    "            folder_queue.append(os.path.join(curr_folder, file))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e004bc",
   "metadata": {},
   "source": [
    "## Some more helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "378c2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# folder: subtrait\n",
    "# traits_already_picked: keep track\n",
    "# returns: chosen image(s), new set of already picked traits\n",
    "def pick_trait_images(folder, traits_already_picked):\n",
    "    \n",
    "    png_files, folder_files = get_compatible_files(folder, traits_already_picked)\n",
    "    \n",
    "    chosen_image = rarity_chooser(png_files)\n",
    "    chosen_folder = rarity_chooser(folder_files)\n",
    "    \n",
    "    traits_picked = []\n",
    "    if chosen_image:\n",
    "        traits_picked = get_traits_for_image(os.path.join(folder, chosen_image))\n",
    "    \n",
    "    # If only PNGs in folder\n",
    "    if len(folder_files) == 0:\n",
    "        return [os.path.join(folder, chosen_image)], traits_already_picked + traits_picked\n",
    "    \n",
    "    # If only folders in folder\n",
    "    elif len(png_files) == 0:\n",
    "        return pick_trait_images(os.path.join(folder, chosen_folder), traits_already_picked)\n",
    "    \n",
    "    # Both PNGs and folders in folder\n",
    "    else:\n",
    "        chosen_image_path = os.path.join(folder, chosen_image)\n",
    "        picked_image, picked_traits = pick_trait_images(os.path.join(folder, chosen_folder), traits_already_picked + traits_picked)\n",
    "        return [chosen_image_path] + picked_image, traits_already_picked + traits_picked + picked_traits\n",
    "                                                        \n",
    "# Randomly choosing for now\n",
    "# elems: list of PNGs/folders\n",
    "def rarity_chooser(elems):\n",
    "    if elems:\n",
    "        return random.choice(elems)\n",
    "    return None\n",
    "\n",
    "# folder:\n",
    "# traits_already_picked:\n",
    "# returns: compatible files within folder that are compatible with traits_already_picked\n",
    "def get_compatible_files(folder, traits_already_picked):\n",
    "    files = os.listdir(folder)\n",
    "    \n",
    "    # Drop pesky ./DSStore files\n",
    "    files = filter(lambda file: not file.startswith('.'), files)\n",
    "    \n",
    "    png_files = []\n",
    "    folder_files = []\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.png'):\n",
    "            trait_name, color, _ = parse_png_filename(file)            \n",
    "        \n",
    "            if is_possible_choice(trait_name, exclusions_dict, traits_already_picked) & \\\n",
    "                is_possible_choice(color, exclusions_dict, traits_already_picked):\n",
    "                png_files.append(file)\n",
    "        else:\n",
    "            if is_possible_choice(file, exclusions_dict, traits_already_picked):\n",
    "                folder_files.append(file)\n",
    "   \n",
    "\n",
    "    return png_files, folder_files\n",
    "\n",
    "def is_possible_choice(entry, exclusions_dict, traits_already_picked):\n",
    "    return (entry not in exclusions_dict or not(set(exclusions_dict[entry]) & set(traits_already_picked)))\n",
    "\n",
    "def get_traits_for_image(chosen_image):\n",
    "    traits = chosen_image.split('/')\n",
    "    trait_name, color, _ = parse_png_filename(traits[-1])\n",
    "    traits[-1] = trait_name\n",
    "    traits.append(color)\n",
    "    return traits\n",
    "    \n",
    "def parse_png_filename(png_filename):\n",
    "    parsed_attributes = png_filename.split('_')\n",
    "    if len(parsed_attributes) == 1:\n",
    "        return parsed_attributes[0], \"\", \"\"\n",
    "    elif len(parsed_attributes) == 2:\n",
    "        return parsed_attributes[0], parsed_attributes[1], \"\"\n",
    "    elif len(parsed_attributes) == 3:\n",
    "        return parsed_attributes[0], parsed_attributes[1], parsed_attributes[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369d5c55",
   "metadata": {},
   "source": [
    "## Generate Babies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2528ab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Traits Ordering **\n",
      "\n",
      "body\n",
      "\n",
      "upper + lower\n",
      "\n",
      "undergarment lower\n",
      "\n",
      "short pants\n",
      "\n",
      "slim pants\n",
      "\n",
      "undergarment upper\n",
      "\n",
      "shoes\n",
      "\n",
      "fat pants\n",
      "\n",
      "short sleeves\n",
      "\n",
      "dress shirt\n",
      "\n",
      "quarter zip\n",
      "\n",
      "hoodies\n",
      "\n",
      "face\n",
      "\n",
      "hats\n",
      "\n",
      "hats + face\n",
      "\n",
      "ears\n",
      "\n",
      "external\n",
      "\n",
      "** Traits Exclusions **\n",
      "\n",
      "surgical masks: ['eaten catalien', 'eaten']\n",
      "\n",
      "baseball cap: ['eaten catalien', 'eaten']\n",
      "\n",
      "spilled carton: ['eaten catalien', 'eaten']\n",
      "\n",
      "beanies: ['eaten catalien', 'eaten']\n",
      "\n",
      "hats + face: ['eaten catalien', 'eaten', 'bucket hats', 'spilled carton', 'beanies']\n",
      "\n",
      "headphones: ['eaten catalien', 'eaten']\n",
      "\n",
      "face: ['eaten catalien', 'eaten']\n",
      "\n",
      "undergarment lower: ['charlesharness_red']\n",
      "\n",
      "undergarment upper: ['charlesharness_red']\n",
      "\n",
      " short pants: ['charlesharness_red']\n",
      "\n",
      "slim pants: ['charlesharness_red', 'short pants']\n",
      "\n",
      "fat pants: ['charlesharness_red', 'short pants', 'slim pants']\n",
      "\n",
      "short sleeves: ['charlesharness_red', 'satchel']\n",
      "\n",
      "dress shirt: ['charlesharness_red', 'satchel', 'short sleeves']\n",
      "\n",
      "hoodies: ['charlesharness_red', 'quarter zip', 'satchel']\n",
      "\n",
      "surgicalmaskundernose: ['syringe']\n",
      "\n",
      "surgicalmaskovernose: ['syringe']\n",
      "\n",
      "walkman: ['headphones', 'spacehelmet']\n",
      "\n",
      "earbleed: ['headphones']\n",
      "\n",
      "blue: ['blue']\n",
      "\n",
      "yellow: ['yellow']\n",
      "\n",
      "red: ['red']\n",
      "\n",
      "quarter zip: ['satchel']\n",
      "\n",
      "satchel: ['satchel']\n",
      "\n",
      "spacehelmet: ['hats', 'ears']\n",
      "\n",
      "pillow: ['chinesemask']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this on update of either 1. layering order and 2. exclusions sheet\n",
    "\n",
    "sheet = service_sheets.spreadsheets()\n",
    "\n",
    "LAYERING_ORDER_SPREADSHEET_ID = '1aHC5g3mPSJGFAPF7UiQXDnV9BBUJCwnx8QHkMMip6uI'\n",
    "LAYERING_ORDER_RANGE = 'A1:A'\n",
    "\n",
    "EXCLUSIONS_SPREADSHEET_ID = '1S3Gbg24gwCmn_2AwThAIlRN9F0PEbA2v1Kn3QkaTjeY'\n",
    "EXCLUSIONS_RANGE = 'A1:B'\n",
    "\n",
    "result = sheet.values().get(spreadsheetId=LAYERING_ORDER_SPREADSHEET_ID, range=LAYERING_ORDER_RANGE).execute()\n",
    "values = result.get('values', [])\n",
    "\n",
    "ordered_traits = [item for sublist in values for item in sublist]\n",
    "\n",
    "print(\"** Traits Ordering **\\n\")\n",
    "for trait in ordered_traits:\n",
    "    print(trait + '\\n')\n",
    "    \n",
    "result = sheet.values().get(spreadsheetId=EXCLUSIONS_SPREADSHEET_ID, range=EXCLUSIONS_RANGE).execute()\n",
    "values = result.get('values', [])\n",
    "\n",
    "exclusions_dict = {}\n",
    "for val in values:\n",
    "    exclusions = val[1].split(',')\n",
    "    for e in exclusions:\n",
    "        if e not in exclusions_dict:\n",
    "                exclusions_dict[e] = []\n",
    "        exclusions_dict[e].append(val[0])\n",
    "\n",
    "print(\"** Traits Exclusions **\\n\")\n",
    "for key, val in exclusions_dict.items():\n",
    "    print(key + \": \" + str(val) + \"\\n\")\n",
    "        \n",
    "images_count = 4\n",
    "\n",
    "num_traits_excluding_body = 5\n",
    "\n",
    "babies_base_filepath = 'Babies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b460ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen traits: ['slim pants', 'fat pants', 'short sleeves', 'ears', 'external']\n",
      "Completed 0_lonely_baby.PNG\n",
      "Chosen traits: ['undergarment lower', 'short pants', 'slim pants', 'hats', 'ears']\n",
      "Completed 1_lonely_baby.PNG\n",
      "Chosen traits: ['upper + lower', 'undergarment lower', 'short pants', 'fat pants', 'external']\n",
      "Completed 2_lonely_baby.PNG\n",
      "Chosen traits: ['undergarment upper', 'shoes', 'fat pants', 'hats', 'ears']\n",
      "Completed 3_lonely_baby.PNG\n",
      "\n",
      "**Image generation complete! **\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageChops\n",
    "\n",
    "# top level\n",
    "def generate_baby(ordered_traits, traits_base_filepath, babies_base_filepath):\n",
    "    \n",
    "    # BFS for trait images selection\n",
    "    picked_trait_images = []\n",
    "    picked_traits = []\n",
    "    base_traits = ordered_traits\n",
    "    \n",
    "    # 1. choose the body trait\n",
    "    body_trait_folder = base_traits.pop(0)\n",
    "    curr_trait_dir = os.path.join(traits_base_filepath, body_trait_folder)\n",
    "    picked_trait_image, picked_traits = pick_trait_images(curr_trait_dir, picked_traits)\n",
    "    picked_trait_images.extend(picked_trait_image)\n",
    "    \n",
    "    # 2. Choose 0-2 face traits\n",
    "    face_traits = ['face', 'hats', 'hats + face', 'ears']\n",
    "    num_face_traits = random.randint(0, 2)\n",
    "    chosen_face_traits = [face_traits[i] for i in sorted(random.sample(range(len(face_traits)), num_face_traits))]\n",
    "    \n",
    "    \n",
    "    # 3. Randomly pick `num_traits_excluding_body` traits\n",
    "    base_traits = list(set(base_traits) - set(face_traits))\n",
    "    num_traits_excluding_body_face = num_traits_excluding_body - num_face_traits\n",
    "    chosen_base_traits = [base_traits[i] for i in sorted(random.sample(range(len(base_traits)), num_traits_excluding_body_face))]\n",
    "    \n",
    "    unsorted_chosen_traits = chosen_base_traits + chosen_face_traits \n",
    "    final_chosen_traits = [trait for x in ordered_traits for trait in unsorted_chosen_traits if trait == x]\n",
    "\n",
    "    print(\"Chosen traits: \" + str(final_chosen_traits))\n",
    "    \n",
    "    while final_chosen_traits:\n",
    "        curr = final_chosen_traits.pop(0)\n",
    "        if curr in exclusions_dict and (set(exclusions_dict[curr]) & set(picked_traits)):\n",
    "            continue\n",
    "            \n",
    "        curr_trait_dir = os.path.join(traits_base_filepath, curr)\n",
    "        \n",
    "        # pick based on exclusions\n",
    "        picked_trait_image, picked_traits = pick_trait_images(curr_trait_dir, picked_traits)\n",
    "        picked_trait_images.extend(picked_trait_image)\n",
    "        \n",
    "    # Layer the images \n",
    "    x, y = Image.open(picked_trait_images[0]).size\n",
    "    final_baby_image = Image.new('RGB', (x, y), (228, 150, 150))\n",
    "    \n",
    "    for trait_image in picked_trait_images:\n",
    "        chosen_image = Image.open(trait_image)\n",
    "        chosen_image = ImageChops.offset(chosen_image, 90, 0)\n",
    "        final_baby_image.paste(chosen_image, (0, 0), chosen_image)\n",
    "    \n",
    "    # Crop to increase baby appearance\n",
    "    final_baby_image = final_baby_image.crop((0, 140, final_baby_image.width - 140, final_baby_image.height))\n",
    "    \n",
    "    # Resize to 1080 * 1080 (Instagram Image dimensions)\n",
    "    final_baby_image = final_baby_image.resize((1080, 1080), Image.LANCZOS) \n",
    "    \n",
    "    return final_baby_image\n",
    "\n",
    "\n",
    "## Generate babies!\n",
    "\n",
    "# Delete previously created baby files\n",
    "if os.path.isdir(babies_base_filepath):\n",
    "    shutil.rmtree(babies_base_filepath)\n",
    "\n",
    "os.mkdir(babies_base_filepath)\n",
    "\n",
    "for i in range(images_count):\n",
    "    final_baby_image = generate_baby(ordered_traits.copy(), traits_base_filepath, babies_base_filepath)\n",
    "    \n",
    "    # Write the image to file\n",
    "    final_baby_image_file = '{:d}_lonely_baby.PNG'.format(i)\n",
    "    final_baby_image.save(os.path.join(babies_base_filepath, final_baby_image_file))\n",
    "    \n",
    "    print(\"Completed \" + final_baby_image_file)\n",
    "\n",
    "print(\"\\n**Image generation complete! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159f473",
   "metadata": {},
   "source": [
    "## Upload Babies to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3490183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading: 8_lonely_baby.PNG\n",
      "Uploading: 7_lonely_baby.PNG\n",
      "Uploading: 0_lonely_baby.PNG\n",
      "Uploading: 1_lonely_baby.PNG\n",
      "Uploading: 9_lonely_baby.PNG\n",
      "Uploading: 6_lonely_baby.PNG\n",
      "Uploading: 3_lonely_baby.PNG\n",
      "Uploading: 4_lonely_baby.PNG\n",
      "Uploading: 5_lonely_baby.PNG\n",
      "Uploading: 2_lonely_baby.PNG\n"
     ]
    }
   ],
   "source": [
    "babies_folder_id = getFolderId(service, babies_base_filepath)\n",
    "deleteFilesInFolder(babies_folder_id)\n",
    "uploadFolder(service, babies_folder_id, os.path.join(babies_base_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c848a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
