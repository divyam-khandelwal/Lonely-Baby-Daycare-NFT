{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ae5b30",
   "metadata": {},
   "source": [
    "## Google Drive Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc49869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Authentication Complete! **\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "\n",
    "creds = None\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "\n",
    "try:\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "    service_sheets = build('sheets', 'v4', credentials=creds)\n",
    "    \n",
    "    print(\"** Authentication Complete! **\")\n",
    "\n",
    "except HttpError as error:\n",
    "    # TODO(developer) - Handle errors from drive API.\n",
    "    print(f'An error occurred: {error}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c13f1",
   "metadata": {},
   "source": [
    "## Google Drive API helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a90598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from os import listdir\n",
    "\n",
    "def getFolderId(service, folderName: str):\n",
    "    query = \"name contains '%s' and mimeType = '%s'\" % (folderName, 'application/vnd.google-apps.folder')\n",
    "\n",
    "    fid = None\n",
    "\n",
    "    if folderName.startswith('+'):\n",
    "        return (folderName[1:])\n",
    "\n",
    "    result = service.files().list(q=query,\n",
    "                                  pageSize=10, pageToken='',\n",
    "                                  fields=\"nextPageToken,files(parents,id,name,mimeType)\").execute()\n",
    "  \n",
    "    if len(result['files']) == 0:\n",
    "        print(\"Folder NOT found\")\n",
    "    else:\n",
    "        folder = result.get('files')[0]\n",
    "        fid = folder['id']\n",
    "\n",
    "    return (fid)\n",
    "\n",
    "    \n",
    "def downloadFolder(service, fileId, destinationFolder):\n",
    "    if not os.path.isdir(destinationFolder):\n",
    "        os.mkdir(path=destinationFolder)\n",
    "\n",
    "    results = service.files().list(\n",
    "        pageSize=300,\n",
    "        q=\"parents in '{0}'\".format(fileId),\n",
    "        fields=\"files(id, name, mimeType)\"\n",
    "        ).execute()\n",
    "\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    for item in items:\n",
    "        itemName = item['name']\n",
    "        itemId = item['id']\n",
    "        itemType = item['mimeType']\n",
    "        filePath = destinationFolder + \"/\" + itemName\n",
    "\n",
    "        if itemType == 'application/vnd.google-apps.folder':\n",
    "            downloadFolder(service, itemId, filePath) # Recursive call\n",
    "            print(\"Downloaded folder: {0}\".format(itemName))\n",
    "        elif not itemType.startswith('application/'):\n",
    "            downloadFile(service, itemId, filePath)\n",
    "        else:\n",
    "            print(\"Unsupported file: {0}\".format(itemName))\n",
    "\n",
    "\n",
    "def downloadFile(service, fileId, filePath):\n",
    "    # Note: The parent folders in filePath must exist\n",
    "    request = service.files().get_media(fileId=fileId)\n",
    "    fh = io.FileIO(filePath, mode='wb')\n",
    "    \n",
    "    try:\n",
    "        downloader = MediaIoBaseDownload(fh, request, chunksize=1024*1024)\n",
    "\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk(num_retries = 2)\n",
    "    finally:\n",
    "        fh.close()\n",
    "        \n",
    "def deleteFilesInFolder(folder_id):\n",
    "    results = service.files().list(\n",
    "        pageSize=300,\n",
    "        q=\"parents in '{0}'\".format(folder_id),\n",
    "        fields=\"files(id, name, mimeType)\"\n",
    "        ).execute()\n",
    "\n",
    "    items = results.get('files', [])\n",
    "    for item in items:\n",
    "        itemId = item['id']\n",
    "        service.files().delete(fileId=itemId).execute()\n",
    "        \n",
    "def uploadFolder(service, folder_id, src_folder):        \n",
    "    for file in listdir(src_folder):\n",
    "        print('Uploading: ' + file)\n",
    "        file_metadata = {'name': file, 'parents': [folder_id]}\n",
    "        media = MediaFileUpload(os.path.join(src_folder, file), mimetype='image/png')\n",
    "        file = service.files().create(body=file_metadata,\n",
    "                                    media_body=media,\n",
    "                                    fields='id').execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec2e81",
   "metadata": {},
   "source": [
    "## Download Trait Files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13192f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "traits_base_filepath = 'Traits'\n",
    "\n",
    "# Delete previously downloaded trait files\n",
    "if os.path.isdir(traits_base_filepath):\n",
    "    shutil.rmtree(traits_base_filepath)\n",
    "\n",
    "traits_folder_id = getFolderId(service, traits_base_filepath)\n",
    "\n",
    "downloadFolder(service, traits_folder_id, traits_base_filepath)\n",
    "\n",
    "print(\"\\n** Download Complete! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705b154",
   "metadata": {},
   "source": [
    "## Print all folders, files (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_queue = [traits_base_filepath]\n",
    "\n",
    "count = 0\n",
    "\n",
    "#Generate rarity definitions\n",
    "while folder_queue:\n",
    "    curr_folder = folder_queue.pop(0)\n",
    "    \n",
    "    files = os.listdir(curr_folder)\n",
    "    files = filter(lambda file: not file.startswith('.'), files)\n",
    "    \n",
    "    for file in files:\n",
    "        print(file)\n",
    "        if file.lower().endswith('.png'):\n",
    "            count += 1\n",
    "        if not file.lower().endswith('.png'):\n",
    "            folder_queue.append(os.path.join(curr_folder, file))\n",
    "            \n",
    "print('\\nPNG Count: ', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e004bc",
   "metadata": {},
   "source": [
    "## Some more helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "378c2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# folder: subtrait\n",
    "# traits_already_picked: keep track\n",
    "# returns: chosen image(s), new set of already picked traits\n",
    "def pick_trait_images(folder, traits_already_picked):\n",
    "    \n",
    "    png_files, folder_files = get_compatible_files(folder, traits_already_picked)\n",
    "\n",
    "    if not png_files and not folder_files:\n",
    "        return None, traits_already_picked\n",
    "    \n",
    "    chosen_image, chosen_folders = rarity_chooser(png_files, folder_files)\n",
    "    chosen_folders = sort_on_list_order(chosen_folders, [\"patch\", \"satchels\", \"bling\"])\n",
    "    \n",
    "    traits_picked = []\n",
    "    if chosen_image:\n",
    "        traits_picked = get_traits_for_image(os.path.join(folder, chosen_image))\n",
    "    \n",
    "    # If only PNGs in folder\n",
    "    if len(folder_files) == 0:\n",
    "        return [os.path.join(folder, chosen_image)], traits_already_picked + traits_picked\n",
    "    \n",
    "    # If only folders in folder\n",
    "    elif len(png_files) == 0:\n",
    "        chosen_folder = chosen_folders[0]\n",
    "        return pick_trait_images(os.path.join(folder, chosen_folder), traits_already_picked)\n",
    "    \n",
    "    # Both PNGs and folders in folder\n",
    "    else:\n",
    "        chosen_image_path = os.path.join(folder, chosen_image)\n",
    "        picked_images_for_folders = []\n",
    "        picked_traits_for_folders = []\n",
    "        for chosen_folder in chosen_folders:\n",
    "            picked_image, picked_traits = pick_trait_images(os.path.join(folder, chosen_folder), traits_already_picked + traits_picked)\n",
    "            picked_images_for_folders.extend(picked_image)\n",
    "            picked_traits_for_folders.extend(picked_traits)\n",
    "        return [chosen_image_path] + picked_images_for_folders, traits_already_picked + traits_picked + picked_traits_for_folders\n",
    "                                                        \n",
    "# elems: list of PNGs/folders\n",
    "def rarity_chooser(png_files, folder_files):\n",
    "    \n",
    "    if not png_files and not folder_files:\n",
    "        return None, [None]\n",
    "    \n",
    "    elif not png_files and folder_files:\n",
    "        return None, [weighted_pick(folder_files)]\n",
    "    \n",
    "    elif not folder_files and png_files:\n",
    "        return weighted_pick(png_files), [None]\n",
    "    \n",
    "    else:\n",
    "        chosen_png = weighted_pick(png_files)\n",
    "        chosen_folders = []\n",
    "        \n",
    "        for file in folder_files:\n",
    "            probability = rarity_dict[file]\n",
    "            if probability and decision(probability):\n",
    "                chosen_folders.append(file)\n",
    "        \n",
    "        return chosen_png, chosen_folders\n",
    "    \n",
    "def weighted_pick(files):\n",
    "    weights = []\n",
    "    for file in files:\n",
    "        if not rarity_dict[file]:\n",
    "            return random.choice(files)\n",
    "        weights.append(int(rarity_dict[file]))\n",
    "    \n",
    "    choices = random.choices(files, weights=weights)\n",
    "    return choices[0]\n",
    "    \n",
    "def decision(probability):\n",
    "    return random.random() < float(probability)\n",
    "\n",
    "# folder:\n",
    "# traits_already_picked:\n",
    "# returns: compatible files within folder that are compatible with traits_already_picked\n",
    "def get_compatible_files(folder, traits_already_picked):\n",
    "    files = os.listdir(folder)\n",
    "    \n",
    "    # Drop pesky ./DSStore files\n",
    "    files = filter(lambda file: not file.startswith('.'), files)\n",
    "    \n",
    "    png_files = []\n",
    "    folder_files = []\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.png'):\n",
    "            trait_name, color, _ = parse_png_filename(file)            \n",
    "        \n",
    "            if is_possible_choice(trait_name, exclusions_dict, traits_already_picked) & \\\n",
    "                is_possible_choice(color, exclusions_dict, traits_already_picked):\n",
    "                png_files.append(file)\n",
    "        else:\n",
    "            if is_possible_choice(file, exclusions_dict, traits_already_picked):\n",
    "                folder_files.append(file)\n",
    "   \n",
    "\n",
    "    return png_files, folder_files\n",
    "\n",
    "def is_possible_choice(entry, exclusions_dict, traits_already_picked):\n",
    "    return (entry not in exclusions_dict or not(set(exclusions_dict[entry]) & set(traits_already_picked)))\n",
    "\n",
    "def get_traits_for_image(chosen_image):\n",
    "    traits = chosen_image.split('/')\n",
    "    trait_name, color, _ = parse_png_filename(traits[-1])\n",
    "    traits[-1] = trait_name\n",
    "    traits.append(color)\n",
    "    return traits\n",
    "    \n",
    "def parse_png_filename(png_filename):\n",
    "    png_filename = os.path.splitext(png_filename)[0]\n",
    "    parsed_attributes = png_filename.split('_')\n",
    "    if len(parsed_attributes) == 1:\n",
    "        return parsed_attributes[0], \"\", \"\"\n",
    "    elif len(parsed_attributes) == 2:\n",
    "        return parsed_attributes[0], parsed_attributes[1], \"\"\n",
    "    elif len(parsed_attributes) == 3:\n",
    "        return parsed_attributes[0], parsed_attributes[1], parsed_attributes[2]\n",
    "    \n",
    "def get_last_index(inp_list, elem):\n",
    "    index = None\n",
    "    for idx, i in enumerate(inp_list):\n",
    "        if i == elem:\n",
    "            index = idx\n",
    "    return index\n",
    "\n",
    "def sort_on_list_order(unsorted_list, sorted_list):\n",
    "    final_list = []\n",
    "    for elem in sorted_list:\n",
    "        if elem in unsorted_list:\n",
    "            final_list.append(elem)\n",
    "    \n",
    "    unsorted_unfound_elems = list(set(unsorted_list) - set(final_list))\n",
    "    final_list.extend(unsorted_unfound_elems)\n",
    "    return final_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369d5c55",
   "metadata": {},
   "source": [
    "## Generate Babies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2528ab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Traits Ordering ingested! **\n",
      "\n",
      "\n",
      "** Traits Exclusions ingested! **\n",
      "\n",
      "\n",
      " Rarities Ingested!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Run this on update of either 1. layering order and 2. exclusions sheet\n",
    "\n",
    "sheet = service_sheets.spreadsheets()\n",
    "\n",
    "LAYERING_ORDER_SPREADSHEET_ID = '1aHC5g3mPSJGFAPF7UiQXDnV9BBUJCwnx8QHkMMip6uI'\n",
    "LAYERING_ORDER_RANGE = 'A1:A'\n",
    "\n",
    "EXCLUSIONS_SPREADSHEET_ID = '1S3Gbg24gwCmn_2AwThAIlRN9F0PEbA2v1Kn3QkaTjeY'\n",
    "EXCLUSIONS_RANGE = 'A1:B'\n",
    "\n",
    "RARITY_DEV_SPREADSHEET_ID = '1NhV9RmhDjme4MA4QMzMOTn9tdDoK-OL6kWK0XSG_G8M'\n",
    "RARITY_SPREADSHEET_ID = '1rvtwtSps-1g35rhXMkt8zU1A7PV62FmFgwPDvZuTLL4'\n",
    "\n",
    "BABIES_TO_IMAGES_SPREADSHEET_ID = '1AgRmweMAzKK7MdHsT9i5ZaRyr7fdhMp2h3zmpab2A6k'\n",
    "\n",
    "RARITY_RANGE = 'A1:B'\n",
    "\n",
    "\n",
    "result = sheet.values().get(spreadsheetId=LAYERING_ORDER_SPREADSHEET_ID, range=LAYERING_ORDER_RANGE).execute()\n",
    "values = result.get('values', [])\n",
    "\n",
    "ordered_traits = [item for sublist in values for item in sublist]\n",
    "\n",
    "print(\"** Traits Ordering ingested! **\\n\")\n",
    "    \n",
    "## Generate warnings for trait exclusions\n",
    "traits_dfs_order = []\n",
    "folder_queue = ordered_traits[::-1]\n",
    "folder_queue = ['Traits/' + path for path in folder_queue]\n",
    "\n",
    "while folder_queue:\n",
    "    curr_folder = folder_queue.pop(-1)\n",
    "    traits_dfs_order.append(Path(curr_folder).stem)\n",
    "    \n",
    "    files = os.listdir(curr_folder)\n",
    "    files = filter(lambda file: not file.startswith('.'), files)\n",
    "    \n",
    "    for file in files:\n",
    "        if file.lower().endswith('.png'):\n",
    "            trait, color, secondary_color = parse_png_filename(file)\n",
    "            traits_dfs_order.append(trait)\n",
    "            if color != \"\":\n",
    "                traits_dfs_order.append(color)\n",
    "            if secondary_color != \"\":\n",
    "                traits_dfs_order.append(secondary_color)\n",
    "        else:\n",
    "             folder_queue.append(os.path.join(curr_folder, file))\n",
    "            \n",
    "\n",
    "result = sheet.values().get(spreadsheetId=EXCLUSIONS_SPREADSHEET_ID, range=EXCLUSIONS_RANGE).execute()\n",
    "values = result.get('values', [])\n",
    "\n",
    "# Warning generation\n",
    "for val in values:\n",
    "    if val[0] not in traits_dfs_order:\n",
    "        print(\"\\n** WARNING -- \", val[0], \"in exclusions not a valid entry\")\n",
    "        break\n",
    "    exclusions = val[1].split(',')\n",
    "    for e in exclusions:\n",
    "        if not get_last_index(traits_dfs_order, e):\n",
    "            print(\"\\n** WARNING -- \", e, \"in exclusions is not a valid entry\")\n",
    "        else:\n",
    "            if not get_last_index(traits_dfs_order, e) > traits_dfs_order.index(val[0]) and e != val[0]:\n",
    "                print(\"\\n** WARNING -- Ordering of \", val[0], \",\", e, \"in exclusions is not valid\")\n",
    "\n",
    "exclusions_dict = {}\n",
    "for val in values:\n",
    "    exclusions = val[1].split(',')\n",
    "    for e in exclusions:\n",
    "        if e not in exclusions_dict:\n",
    "                exclusions_dict[e] = []\n",
    "        exclusions_dict[e].append(val[0])\n",
    "\n",
    "print(\"\\n** Traits Exclusions ingested! **\\n\")    \n",
    "\n",
    "# Rarity ingestion\n",
    "result = sheet.values().get(spreadsheetId=RARITY_DEV_SPREADSHEET_ID, range=RARITY_RANGE).execute()\n",
    "values = result.get('values', [])\n",
    "\n",
    "rarity_dict = {}\n",
    "for val in values:\n",
    "    if len(val) == 1:\n",
    "        rarity_dict[val[0]] = None\n",
    "    elif len(val) == 2:\n",
    "        rarity_dict[val[0]] = val[1]\n",
    "    \n",
    "\n",
    "print(\"\\n Rarities Ingested!\")\n",
    "\n",
    "images_count = 20\n",
    "\n",
    "num_traits_excluding_body = 9\n",
    "\n",
    "pagination_chunk = 50\n",
    "\n",
    "babies_base_filepath = 'Babies'\n",
    "\n",
    "traits_base_filepath = 'Traits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b460ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen traits: ['short pants', 'slim pants', 'short sleeves', 'dress shirt', 'quarter zip', 'hoodies', 'hats', 'external']\n",
      "2 cells appended.\n",
      "Completed 0_lonely_baby.PNG\n",
      "Chosen traits: ['undergarment lower', 'short pants', 'slim pants', 'fat pants', 'short sleeves', 'hoodies']\n",
      "2 cells appended.\n",
      "Completed 1_lonely_baby.PNG\n",
      "Chosen traits: ['slim pants', 'fat pants', 'short sleeves', 'quarter zip', 'hoodies', 'hats']\n",
      "2 cells appended.\n",
      "Completed 2_lonely_baby.PNG\n",
      "Chosen traits: ['slim pants', 'undergarment upper', 'short sleeves', 'quarter zip', 'hoodies', 'parka', 'hats']\n",
      "2 cells appended.\n",
      "Completed 3_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'fat pants', 'short sleeves', 'dress shirt', 'hoodies', 'external']\n",
      "2 cells appended.\n",
      "Completed 4_lonely_baby.PNG\n",
      "Chosen traits: ['slim pants', 'undergarment upper', 'fat pants', 'short sleeves', 'face', 'ears']\n",
      "2 cells appended.\n",
      "Completed 5_lonely_baby.PNG\n",
      "Chosen traits: ['undergarment lower', 'short pants', 'slim pants', 'fat pants', 'short sleeves', 'dress shirt', 'quarter zip']\n",
      "2 cells appended.\n",
      "Completed 6_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'undergarment upper', 'fat pants', 'quarter zip', 'ears']\n",
      "2 cells appended.\n",
      "Completed 7_lonely_baby.PNG\n",
      "Chosen traits: ['fat pants', 'short sleeves', 'dress shirt', 'quarter zip', 'ears']\n",
      "2 cells appended.\n",
      "Completed 8_lonely_baby.PNG\n",
      "Chosen traits: ['slim pants', 'undergarment upper', 'short sleeves', 'quarter zip', 'hoodies', 'parka', 'glasses']\n",
      "2 cells appended.\n",
      "Completed 9_lonely_baby.PNG\n",
      "Chosen traits: ['undergarment lower', 'short pants', 'short sleeves', 'ears', 'external']\n",
      "2 cells appended.\n",
      "Completed 10_lonely_baby.PNG\n",
      "Chosen traits: ['undergarment lower', 'short pants', 'slim pants', 'dress shirt', 'quarter zip', 'hoodies', 'hats + face']\n",
      "2 cells appended.\n",
      "Completed 11_lonely_baby.PNG\n",
      "Chosen traits: ['upper + lower', 'short pants', 'slim pants', 'fat pants', 'short sleeves', 'quarter zip']\n",
      "2 cells appended.\n",
      "Completed 12_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'shoes', 'fat pants', 'short sleeves', 'quarter zip', 'hoodies', 'glasses', 'ears']\n",
      "2 cells appended.\n",
      "Completed 13_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'undergarment upper', 'fat pants', 'dress shirt', 'quarter zip', 'hoodies', 'hats', 'ears']\n",
      "2 cells appended.\n",
      "Completed 14_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'fat pants', 'hoodies', 'ears']\n",
      "2 cells appended.\n",
      "Completed 15_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'undergarment upper', 'fat pants', 'dress shirt', 'hoodies', 'glasses', 'face']\n",
      "2 cells appended.\n",
      "Completed 16_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'fat pants', 'short sleeves', 'dress shirt', 'quarter zip', 'hoodies', 'glasses', 'hats']\n",
      "2 cells appended.\n",
      "Completed 17_lonely_baby.PNG\n",
      "Chosen traits: ['slim pants', 'undergarment upper', 'short sleeves', 'dress shirt', 'hoodies', 'glasses']\n",
      "2 cells appended.\n",
      "Completed 18_lonely_baby.PNG\n",
      "Chosen traits: ['short pants', 'slim pants', 'undergarment upper', 'short sleeves', 'quarter zip', 'hoodies', 'hats']\n",
      "2 cells appended.\n",
      "Completed 19_lonely_baby.PNG\n",
      "\n",
      "**Image generation complete! **\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageChops\n",
    "import shutil\n",
    "\n",
    "\n",
    "# top level\n",
    "def generate_baby(ordered_traits, traits_base_filepath, babies_base_filepath):\n",
    "    \n",
    "    # BFS for trait images selection\n",
    "    picked_trait_images = []\n",
    "    picked_traits = []\n",
    "    base_traits = ordered_traits\n",
    "    \n",
    "    # 1. Choose background\n",
    "    background_trait_folder = base_traits.pop(0)\n",
    "    curr_trait_dir = os.path.join(traits_base_filepath, background_trait_folder)\n",
    "    picked_trait_image, picked_traits = pick_trait_images(curr_trait_dir, picked_traits)\n",
    "    picked_trait_images.extend(picked_trait_image)\n",
    "\n",
    "    # 2. choose the body trait\n",
    "    body_trait_folder = base_traits.pop(0)\n",
    "    curr_trait_dir = os.path.join(traits_base_filepath, body_trait_folder)\n",
    "    picked_trait_image, picked_traits = pick_trait_images(curr_trait_dir, picked_traits)\n",
    "    picked_trait_images.extend(picked_trait_image)\n",
    "    \n",
    "    # 3. Choose face traits\n",
    "    face_traits = ['glasses', 'hats', 'face', 'hats + face', 'ears']\n",
    "    picked_image = Path(picked_trait_image[0]).stem\n",
    "    num_face_traits = 0\n",
    "    chosen_face_traits = []\n",
    "    if parse_png_filename(picked_image)[0] == 'bodyneutral':\n",
    "        num_face_traits = random.randint(2, 3)\n",
    "        for i in range(num_face_traits):\n",
    "            _, [chosen_trait] = rarity_chooser([], face_traits)\n",
    "            chosen_face_traits.append(chosen_trait)\n",
    "    else:\n",
    "        num_face_traits = random.randint(0, 2)\n",
    "        for _ in range(num_face_traits):\n",
    "            _, [chosen_trait] = rarity_chooser([], face_traits)\n",
    "            chosen_face_traits.append(chosen_trait)\n",
    "#     chosen_face_traits = sort_on_list_order(chosen_face_traits, face_traits)\n",
    "#     chosen_face_traits = [face_traits[i] for i in sorted(random.sample(range(len(face_traits)), num_face_traits))]\n",
    "    \n",
    "    \n",
    "    # 4. Randomly pick `num_traits_excluding_body` traits\n",
    "    base_traits = list(set(base_traits) - set(face_traits))\n",
    "    num_traits_excluding_body_face = num_traits_excluding_body - num_face_traits\n",
    "    chosen_base_traits = []\n",
    "    for _ in range(num_traits_excluding_body_face):\n",
    "        _, [chosen_trait] = rarity_chooser([], base_traits)\n",
    "        chosen_base_traits.append(chosen_trait)\n",
    "#     chosen_base_traits = sort_on_list_order(chosen_base_traits, ordered_traits)\n",
    "#     chosen_base_traits = [base_traits[i] for i in sorted(random.sample(range(len(base_traits)), num_traits_excluding_body_face))]\n",
    "    \n",
    "    unsorted_chosen_traits = chosen_base_traits + chosen_face_traits \n",
    "#     final_chosen_traits = [trait for x in ordered_traits for trait in unsorted_chosen_traits if trait == x]\n",
    "    final_chosen_traits = sort_on_list_order(unsorted_chosen_traits, ordered_traits)\n",
    "    \n",
    "    print(\"Chosen traits: \" + str(final_chosen_traits))\n",
    "    \n",
    "    while final_chosen_traits:\n",
    "        curr = final_chosen_traits.pop(0)\n",
    "        if curr in exclusions_dict and (set(exclusions_dict[curr]) & set(picked_traits)):\n",
    "            continue\n",
    "            \n",
    "        curr_trait_dir = os.path.join(traits_base_filepath, curr)\n",
    "        \n",
    "        # pick based on exclusions\n",
    "        picked_trait_image, picked_traits = pick_trait_images(curr_trait_dir, picked_traits)\n",
    "        if picked_trait_image: \n",
    "            picked_trait_images.extend(picked_trait_image)\n",
    "        \n",
    "        \n",
    "    # Layer the images \n",
    "    x, y = Image.open(picked_trait_images[0]).size\n",
    "    final_baby_image = Image.new('RGB', (x, y), (228, 150, 150))\n",
    "    \n",
    "    for trait_image in picked_trait_images:\n",
    "        chosen_image = Image.open(trait_image)\n",
    "        chosen_image = ImageChops.offset(chosen_image, 90, 0)\n",
    "        final_baby_image.paste(chosen_image, (0, 0), chosen_image)\n",
    "    \n",
    "    # Crop to increase baby appearance\n",
    "    final_baby_image = final_baby_image.crop((0, 140, final_baby_image.width - 140, final_baby_image.height))\n",
    "    \n",
    "    return final_baby_image, picked_trait_images\n",
    "\n",
    "def upload_files_with_pagination():\n",
    "    # Upload babies to drive\n",
    "    babies_folder_id = getFolderId(service, babies_base_filepath)\n",
    "    uploadFolder(service, babies_folder_id, os.path.join(babies_base_filepath))\n",
    "        \n",
    "    # Delete babies on file\n",
    "    shutil.rmtree(babies_base_filepath)\n",
    "    os.mkdir(babies_base_filepath)\n",
    "    \n",
    "def clear_babies_to_images_mapping_spreadsheet():\n",
    "    body = {}\n",
    "    resultClear = sheet.values().clear(spreadsheetId=BABIES_TO_IMAGES_SPREADSHEET_ID, range='A:B',\n",
    "                                                       body=body).execute()\n",
    "\n",
    "## Generate babies!\n",
    "\n",
    "# Delete previously created baby files\n",
    "if os.path.isdir(babies_base_filepath):\n",
    "    shutil.rmtree(babies_base_filepath)\n",
    "    \n",
    "clear_babies_to_images_mapping_spreadsheet()\n",
    "\n",
    "os.mkdir(babies_base_filepath)\n",
    "\n",
    "for i in range(images_count):\n",
    "    \n",
    "    if i != 0 and i % pagination_chunk == 0:\n",
    "        upload_files_with_pagination()\n",
    "        \n",
    "    final_baby_image, picked_images = generate_baby(ordered_traits.copy(), traits_base_filepath, babies_base_filepath)\n",
    "    \n",
    "    # Write the image to file\n",
    "    final_baby_image_file = '{:d}_lonely_baby.PNG'.format(i)\n",
    "    final_baby_image.save(os.path.join(babies_base_filepath, final_baby_image_file))\n",
    "    \n",
    "    # Update babies to images mapping spreadsheet\n",
    "    picked_images_str = \",\".join(picked_images)\n",
    "    values = [[final_baby_image_file, picked_images_str]]\n",
    "    body = {\n",
    "        'values': values\n",
    "    }\n",
    "    result = sheet.values().append(\n",
    "        spreadsheetId=BABIES_TO_IMAGES_SPREADSHEET_ID, range='A:B',\n",
    "        valueInputOption='RAW', body=body).execute()\n",
    "    print('{0} cells appended.'.format(result\n",
    "                                       .get('updates')\n",
    "                                       .get('updatedCells')))\n",
    "    \n",
    "    print(\"Completed \" + final_baby_image_file)\n",
    "\n",
    "print(\"\\n**Image generation complete! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159f473",
   "metadata": {},
   "source": [
    "## Upload Babies to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# babies_folder_id = getFolderId(service, babies_base_filepath)\n",
    "# deleteFilesInFolder(babies_folder_id)\n",
    "# uploadFolder(service, babies_folder_id, os.path.join(babies_base_filepath))\n",
    "\n",
    "# babies_folder_id = getFolderId(service, babies_base_filepath)\n",
    "# deleteFilesInFolder(babies_folder_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c848a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86e091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
